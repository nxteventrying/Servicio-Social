{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f28533-efa5-4f3f-980b-f8255342f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e96802b-349f-4271-b07a-7866cf8e55d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be0abc6-1389-44f8-ad16-ca96200b35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate SD1 and SD2\n",
    "def calculate_sd1_sd2(series):\n",
    "    n = len(series)\n",
    "    mean_rr = np.mean(series)\n",
    "    \n",
    "    # Calculate SD1\n",
    "    diff_rr = np.diff(series) / np.sqrt(2)\n",
    "    sd1 = np.sqrt(np.sum(diff_rr**2) / (n - 1))\n",
    "    \n",
    "    # Calculate SD2\n",
    "    sd2_term = (series[:-1] + series[1:] - 2 * mean_rr) / np.sqrt(2)\n",
    "    sd2 = np.sqrt(np.sum(sd2_term**2) / (n - 1))\n",
    "    \n",
    "    return sd1, sd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d15d32fa-d32f-4b8b-9772-30b1e5db30cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mloadtxt(file_path)\n\u001b[1;32m      2\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m data[data[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Filter out zero values\u001b[39;00m\n\u001b[1;32m      3\u001b[0m time_data \u001b[38;5;241m=\u001b[39m filtered_data[:, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_path' is not defined"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(file_path)\n",
    "filtered_data = data[data[:, 1] != 0]  # Filter out zero values\n",
    "time_data = filtered_data[:, 0]\n",
    "hrv_data = filtered_data[:, 1]\n",
    "# Calculate statistics\n",
    "stats = calculate_interval_statistics(time_data, hrv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1df0ddfe-7e11-4f0c-9c86-2f7c6bb7eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate RR mean, SD1, SD2, and standard deviation for each interval\n",
    "def calculate_interval_statistics(time_data, hrv_data):\n",
    "    intervals = {\n",
    "        'Rest': (1, 6),\n",
    "        'Exercise': (14, 19),\n",
    "        'Recovery': (25, 30)\n",
    "    }\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    for interval, (start, end) in intervals.items():\n",
    "        mask = (time_data >= start) & (time_data < end)\n",
    "        interval_data = hrv_data[mask]\n",
    "        \n",
    "        if len(interval_data) > 1:  # Ensure there's enough data for SD calculation\n",
    "            rr_mean = np.mean(interval_data)\n",
    "            sd1, sd2 = calculate_sd1_sd2(interval_data)\n",
    "            rr_std = np.std(interval_data)  # Calculate standard deviation\n",
    "            stats[interval] = {\n",
    "                'Mean': rr_mean,\n",
    "                'Standard Deviation': rr_std,\n",
    "                'SD1': sd1,\n",
    "                'SD2': sd2\n",
    "            }\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebd58ed3-a41f-4dfe-b52c-dabc75e52a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(ax, time_data, hrv_data, filename, stats):\n",
    "    # Define timeline markers\n",
    "    Rest = 7\n",
    "    Exercise = 20\n",
    "    Recovery = 32\n",
    "\n",
    "    colors = {'Rest': 'blue', 'Exercise': 'orange', 'Recovery': 'purple'}\n",
    "    \n",
    "    # Plot each point with color-coded intervals\n",
    "    for i in range(len(time_data)):\n",
    "        if time_data[i] < Rest:\n",
    "            color = colors['Rest']\n",
    "        elif time_data[i] < Exercise:\n",
    "            color = colors['Exercise']\n",
    "        elif time_data[i] < Recovery:\n",
    "            color = colors['Recovery']\n",
    "        else:\n",
    "            continue\n",
    "        ax.plot(time_data[i], hrv_data[i], '.', color=color)\n",
    "    \n",
    "    # Plot green vertical lines to mark intervals\n",
    "    ax.axhline(y= hrv_data.min(), color='r', linestyle='-')\n",
    "\n",
    "    ax.axvline(x=1, color='g', linestyle='-')\n",
    "    ax.axvline(x=6, color='g', linestyle='-')\n",
    "    ax.axvline(x=14, color='g', linestyle='--')\n",
    "    ax.axvline(x=19, color='g', linestyle='--')\n",
    "    ax.axvline(x=25, color='g', linestyle='-')\n",
    "    ax.axvline(x=30, color='g', linestyle='-')\n",
    "    \n",
    "    # Modify the region texts dynamically based on calculated stats\n",
    "    region_positions = {'Rest': 3.5,\n",
    "                        'Exercise': 16.5,\n",
    "                        'Recovery': 27.5\n",
    "                       }\n",
    "\n",
    "    # Loop over regions and stats\n",
    "    for region, x_pos in region_positions.items():\n",
    "        if region in stats:  # Check if stats for the region exist\n",
    "            rr_mean = stats[region]['Mean']\n",
    "            rr_std = stats[region]['Standard Deviation']\n",
    "            text_str = f\"Mean RR: {rr_mean:.2f} ms\\nSTD RR: {rr_std:.2f} ms\"\n",
    "            # Add the text for each region at the corresponding position\n",
    "            ax.text(x_pos, hrv_data.max() + 10, text_str, fontsize=10, \n",
    "                    verticalalignment='top', horizontalalignment='center',\n",
    "                    bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    # Set axis limits, title, labels, and grid\n",
    "    ax.set_ylim(hrv_data.min() - 50, hrv_data.max() + 50)\n",
    "    ax.set_title(f\"RR {filename}\")  # Include filename in title\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"RR (ms)\")\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3559a69-7675-4e61-86dd-2c54dc550cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poincare plot function with color coding and filename in title\n",
    "def poincare_plot(ax, hrv_data, time_data, filename):\n",
    "    x = []\n",
    "    y = []\n",
    "    colors = {'Rest': 'blue', 'Exercise': 'orange', 'Recovery': 'purple'}\n",
    "    color_x = []\n",
    "\n",
    "    Rest = 7\n",
    "    Exercise = 20\n",
    "    Recovery = 32\n",
    "\n",
    "    for i in range(len(hrv_data) - 1):\n",
    "        x.append(hrv_data[i])     # RR(n)\n",
    "        y.append(hrv_data[i + 1]) # RR(n+1)\n",
    "        # Determine color based on the time of RR(n) and RR(n+1)\n",
    "        if time_data[i] < Rest:\n",
    "            color_x.append(colors['Rest'])\n",
    "        elif time_data[i] < Exercise:\n",
    "            color_x.append(colors['Exercise'])\n",
    "        elif time_data[i] < Recovery:\n",
    "            color_x.append(colors['Recovery'])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    ax.scatter(x, y, c=color_x, s=10)  # Use c=color_x directly\n",
    "    ax.set_title(f\"PoincarÃ© {filename}\")  # Include filename in title\n",
    "    ax.set_xlabel(\"RR(n)\")\n",
    "    ax.set_ylabel(\"RR(n+1)\")\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80e4e8b-ebab-4c1f-924e-b16aef30bd72",
   "metadata": {},
   "source": [
    "# Modified main function to include limit on number of images\n",
    "def process_files(data_folder, output_folder, csv_filename, n=None):\n",
    "    txt_files = glob.glob(os.path.join(data_folder, \"*.txt\"))\n",
    "    \n",
    "    # List all .txt files in the folder\n",
    "    filenames = os.listdir(data_folder)\n",
    "    \n",
    "    # Group files by prefix up to the first number\n",
    "    file_groups = defaultdict(list)\n",
    "    pattern = re.compile(r\"([a-zA-Z]+)(\\d+)\")  # Regex to extract the prefix and number\n",
    "    \n",
    "    # Process each filename\n",
    "    for filename in filenames:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            prefix = match.group(1)\n",
    "            number = int(match.group(2))  # Extract the number\n",
    "            file_groups[prefix].append((filename, number))\n",
    "\n",
    "    # Sort each group by the number part\n",
    "    sorted_filenames = []\n",
    "    for prefix, files in file_groups.items():\n",
    "        sorted_files = sorted(files, key=lambda x: x[1])  # Sort by the number\n",
    "        sorted_filenames.extend([file[0] for file in sorted_files])  # Add sorted filenames to the list\n",
    "    \n",
    "    # Apply the limit on the number of files to process\n",
    "    if n is not None:\n",
    "        sorted_filenames = sorted_filenames[:n]  # Limit the number of files processed\n",
    "    \n",
    "    # Prepare CSV file for writing\n",
    "    with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        # Write a single header row\n",
    "        writer.writerow([\n",
    "            \"File\", \n",
    "            \"Mean_RR_Rest\", \"STD_RR_Rest\",\n",
    "            \"Mean_RR_Exercise\",\"STD_RR_Exercise\",\n",
    "            \"Mean_RR_Recovery\", \"STD_RR_Recovery\",\n",
    "            \"SD1_Rest\", \"SD2_Rest\",\n",
    "            \"SD1_Exercise\", \"SD2_Exercise\",\n",
    "            \"SD1_Recovery\", \"SD2_Recovery\"\n",
    "        ])\n",
    "        \n",
    "        # List to track problematic files\n",
    "        failed_files = []\n",
    "        \n",
    "        # Loop through each sorted file and process\n",
    "        for filename in sorted_filenames:\n",
    "            file_path = os.path.join(data_folder, filename)  # Get the full path of the file\n",
    "            try:\n",
    "                # Try loading the file, catching any errors in the process\n",
    "                data = np.loadtxt(file_path)\n",
    "                filtered_data = data[data[:, 1] != 0]  # Filter out zero values\n",
    "                time_data = filtered_data[:, 0]\n",
    "                hrv_data = filtered_data[:, 1]\n",
    "                \n",
    "                # Calculate statistics\n",
    "                stats = calculate_interval_statistics(time_data, hrv_data)\n",
    "                \n",
    "                # Collect data for all regions (Rest, Exercise, Recovery)\n",
    "                row = [os.path.basename(file_path)]\n",
    "\n",
    "                # Append SD1 and SD2 for each region\n",
    "                for region in ['Rest', 'Exercise', 'Recovery']:\n",
    "                    if region in stats:\n",
    "                        row.extend([\n",
    "                            stats[region]['Mean'],\n",
    "                            stats[region]['Standard Deviation'],\n",
    "                            stats[region]['SD1'], \n",
    "                            stats[region]['SD2']\n",
    "                        ])\n",
    "                    else:\n",
    "                        row.extend([None, None])  # If not enough data for the region, append Nones\n",
    "                \n",
    "                # Write the collected row for this file\n",
    "                writer.writerow(row)\n",
    "                \n",
    "                # Create a subplot for side-by-side plots\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(30, 8))  # 1 row, 2 columns\n",
    "                \n",
    "                # Extract the filename without extension\n",
    "                filename_without_extension\n",
    "                \n",
    "                # Extract the filename without extension\n",
    "                filename_without_extension = os.path.splitext(filename)[0]\n",
    "                \n",
    "                # Plot the data on the left subplot\n",
    "                plot_data(axes[0], time_data, hrv_data, filename_without_extension, stats)\n",
    "                \n",
    "                # Plot the PoincarÃ© plot on the right subplot\n",
    "                poincare_plot(axes[1], hrv_data, time_data, filename_without_extension)\n",
    "                \n",
    "                # Save the figure to the output folder\n",
    "                output_file_path = os.path.join(output_folder, f\"{filename_without_extension}.png\")\n",
    "                plt.savefig(output_file_path)\n",
    "                \n",
    "                # Close the figure to free up memory\n",
    "                plt.close(fig)\n",
    "            \n",
    "            except Exception as e:\n",
    "                # Handle any issues during file processing\n",
    "                failed_files.append(filename)\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "    \n",
    "    # If there were problematic files, print a summary\n",
    "    if failed_files:\n",
    "        print(f\"The following files encountered errors: {failed_files}\")\n",
    "    else:\n",
    "        print(\"All files processed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a24c60b-e39b-4e13-8c9f-f295b48beacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(data_folder, output_folder, csv_filename, n):\n",
    "    txt_files = glob.glob(os.path.join(data_folder, \"*.txt\"))\n",
    "    \n",
    "    # List all .txt files in the folder\n",
    "    filenames = os.listdir(data_folder)\n",
    "    \n",
    "    # Group files by prefix up to the first number\n",
    "    file_groups = defaultdict(list)\n",
    "    pattern = re.compile(r\"([a-zA-Z]+)(\\d+)\")  # Regex to extract the prefix and number\n",
    "    \n",
    "    # Process each filename\n",
    "    for filename in filenames:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            prefix = match.group(1)\n",
    "            number = int(match.group(2))  # Extract the number\n",
    "            file_groups[prefix].append((filename, number))\n",
    "\n",
    "    # Sort each group by the number part\n",
    "    sorted_filenames = []\n",
    "    for prefix, files in file_groups.items():\n",
    "        sorted_files = sorted(files, key=lambda x: x[1])  # Sort by the number\n",
    "        sorted_filenames.extend([file[0] for file in sorted_files])  # Add sorted filenames to the list\n",
    "    \n",
    "    # Prepare CSV file for writing\n",
    "    with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        # Write a single header row\n",
    "        writer.writerow([\n",
    "            \"File\", \n",
    "            \"Mean_RR_Rest\", \"STD_RR_Rest\",\n",
    "            \"Mean_RR_Exercise\",\"STD_RR_Exercise\",\n",
    "            \"Mean_RR_Recovery\", \"STD_RR_Recovery\",\n",
    "            \"SD1_Rest\", \"SD2_Rest\",\n",
    "            \"SD1_Exercise\", \"SD2_Exercise\",\n",
    "            \"SD1_Recovery\", \"SD2_Recovery\"\n",
    "        ])\n",
    "        \n",
    "        # List to track problematic files\n",
    "        failed_files = []\n",
    "        \n",
    "        # Limit processing to `n` files\n",
    "        file_count = 0\n",
    "        \n",
    "        # Loop through each sorted file and process\n",
    "        for filename in sorted_filenames:\n",
    "            file_path = os.path.join(data_folder, filename)  # Get the full path of the file\n",
    "            filename_without_extension = os.path.splitext(os.path.basename(file_path))[0]  # Extract filename here\n",
    "            try:\n",
    "                # Try loading the file, catching any errors in the process\n",
    "                data = np.loadtxt(file_path)\n",
    "                filtered_data = data[data[:, 1] != 0]  # Filter out zero values\n",
    "                time_data = filtered_data[:, 0]\n",
    "                hrv_data = filtered_data[:, 1]\n",
    "                \n",
    "                # Calculate statistics\n",
    "                stats = calculate_interval_statistics(time_data, hrv_data)\n",
    "                \n",
    "                # Collect data for all regions (Rest, Exercise, Recovery)\n",
    "                row = [os.path.basename(file_path)]\n",
    "\n",
    "                # Append SD1 and SD2 for each region\n",
    "                for region in ['Rest', 'Exercise', 'Recovery']:\n",
    "                    if region in stats:\n",
    "                        row.extend([\n",
    "                            stats[region]['Mean'],\n",
    "                            stats[region]['Standard Deviation'],\n",
    "                            stats[region]['SD1'], \n",
    "                            stats[region]['SD2']\n",
    "                        ])\n",
    "                    else:\n",
    "                        row.extend([None, None])  # If not enough data for the region, append Nones\n",
    "                \n",
    "                # Write the collected row for this file\n",
    "                writer.writerow(row)\n",
    "                \n",
    "                # Create a subplot for side-by-side plots\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(30, 8))  # 1 row, 2 columns\n",
    "                \n",
    "                # Plot data and Poincare plot side by side with filename in title\n",
    "                plot_data(axes[0], time_data, hrv_data, filename_without_extension, stats)  # HRV data on the left\n",
    "                poincare_plot(axes[1], hrv_data, time_data, filename_without_extension)  # Poincare plot on the right\n",
    "                \n",
    "                # Adjust layout and save the plot\n",
    "                plt.subplots_adjust(wspace=1)\n",
    "                plot_filename = os.path.join(output_folder, filename_without_extension + '_subplot.png')\n",
    "                plt.savefig(plot_filename)\n",
    "                plt.close()\n",
    "\n",
    "                file_count += 1\n",
    "                if file_count >= n:\n",
    "                    break  # Stop after processing `n` files\n",
    "\n",
    "            except ValueError as ve:\n",
    "                print(f\"ValueError for file {file_path}: {ve}\")\n",
    "                failed_files.append(file_path)  # Add file to failed list\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file_path}: {e}\")\n",
    "                failed_files.append(file_path)  # Add file to failed list\n",
    "\n",
    "    # Print the list of files that couldn't be processed\n",
    "    if failed_files:\n",
    "        print(\"\\nThe following files encountered errors:\")\n",
    "        for failed_file in failed_files:\n",
    "            print(failed_file)\n",
    "    else:\n",
    "        print(\"\\nAll files processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ac448c-4394-4fdc-8c7c-619186dad7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set your parameters here\n",
    "n = 5  # Limit for the number of images to process\n",
    "data_folder = \"Active\"  # Folder with .txt files\n",
    "output_folder = \"Plots_Wachi\"  # Folder to save plots\n",
    "csv_filename = \"Wachi.csv\"  # Output CSV file\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Run the main file processing function\n",
    "process_files(data_folder, output_folder, csv_filename, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91f6190d-1e25-409b-beed-b6a25cf8b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(data_folder, output_folder, csv_filename, filename):\n",
    "    file_path = os.path.join(data_folder, filename)  # Get the full path of the file\n",
    "    filename_without_extension = os.path.splitext(os.path.basename(file_path))[0]  # Extract filename without extension\n",
    "    \n",
    "    # Prepare CSV file for writing (or appending)\n",
    "    with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        \n",
    "        # Write a single header row (optional: only if the CSV is new)\n",
    "        writer.writerow([\n",
    "            \"File\", \n",
    "            \"Mean_RR_Rest\", \"STD_RR_Rest\",\n",
    "            \"Mean_RR_Exercise\",\"STD_RR_Exercise\",\n",
    "            \"Mean_RR_Recovery\", \"STD_RR_Recovery\",\n",
    "            \"SD1_Rest\", \"SD2_Rest\",\n",
    "            \"SD1_Exercise\", \"SD2_Exercise\",\n",
    "            \"SD1_Recovery\", \"SD2_Recovery\"\n",
    "        ])\n",
    "        \n",
    "        # Try loading the file and processing the data\n",
    "        try:\n",
    "            data = np.loadtxt(file_path)\n",
    "            filtered_data = data[data[:, 1] != 0]  # Filter out zero values\n",
    "            time_data = filtered_data[:, 0]\n",
    "            hrv_data = filtered_data[:, 1]\n",
    "            \n",
    "            # Calculate statistics\n",
    "            stats = calculate_interval_statistics(time_data, hrv_data)\n",
    "            \n",
    "            # Collect data for all regions (Rest, Exercise, Recovery)\n",
    "            row = [os.path.basename(file_path)]\n",
    "\n",
    "            # Append SD1 and SD2 for each region\n",
    "            for region in ['Rest', 'Exercise', 'Recovery']:\n",
    "                if region in stats:\n",
    "                    row.extend([\n",
    "                        stats[region]['Mean'],\n",
    "                        stats[region]['Standard Deviation'],\n",
    "                        stats[region]['SD1'], \n",
    "                        stats[region]['SD2']\n",
    "                    ])\n",
    "                else:\n",
    "                    row.extend([None, None])  # If not enough data for the region, append Nones\n",
    "            \n",
    "            # Write the collected row for this file\n",
    "            writer.writerow(row)\n",
    "\n",
    "            print(f\"File {filename} processed successfully!\")\n",
    "            \n",
    "        except ValueError as ve:\n",
    "            print(f\"ValueError for file {file_path}: {ve}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09ad832e-9743-4f61-933e-7910695d4e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File VPS50W.txt processed successfully!\n"
     ]
    }
   ],
   "source": [
    "data_folder = 'All'\n",
    "output_folder = 'Run'\n",
    "csv_filename = 'Run.csv'\n",
    "filename = 'VPS50W.txt'  # The file you want to process\n",
    "\n",
    "process_file(data_folder, output_folder, csv_filename, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0455873d-a05d-4e24-8515-bf468fc97295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(data_folder, output_folder, csv_filename, filename):\n",
    "    # Construct full file path\n",
    "    file_path = os.path.join(data_folder, filename)  # Get the full path of the file\n",
    "    filename_without_extension = os.path.splitext(os.path.basename(file_path))[0]  # Extract filename without extension\n",
    "    return file_path,filename_without_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff906d5f-ec8e-4f19-8171-629aea706eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All/VPS50W.txt', 'VPS50W')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_file(data_folder, output_folder, csv_filename, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d62d9fb2-9cd9-417b-8468-595541496f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Prepare CSV file for writing (or appending)\n",
    "    with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        \n",
    "        # Write a single header row (optional: only if the CSV is new)\n",
    "        writer.writerow([\n",
    "            \"File\", \n",
    "            \"Mean_RR_Rest\", \"STD_RR_Rest\",\n",
    "            \"Mean_RR_Exercise\",\"STD_RR_Exercise\",\n",
    "            \"Mean_RR_Recovery\", \"STD_RR_Recovery\",\n",
    "            \"SD1_Rest\", \"SD2_Rest\",\n",
    "            \"SD1_Exercise\", \"SD2_Exercise\",\n",
    "            \"SD1_Recovery\", \"SD2_Recovery\"\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fad15a7b-9b0a-450e-bf4d-23a3b95d7018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='Run.csv' mode='w' encoding='UTF-8'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "453d8835-9770-403e-ae67-a24e6a0c508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def process_file(data_folder, output_folder, csv_filename, filename):\n",
    "    # Step 1: Construct full file path and extract filename without extension\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "    filename_without_extension = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    print(f\"Processing file: {file_path}\")\n",
    "    \n",
    "    # Step 2: Prepare CSV file for writing\n",
    "    with open(csv_filename, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        \n",
    "        # Write the header row\n",
    "        header = [\n",
    "            \"File\", \n",
    "            \"Mean_RR_Rest\", \"STD_RR_Rest\",\n",
    "            \"Mean_RR_Exercise\", \"STD_RR_Exercise\",\n",
    "            \"Mean_RR_Recovery\", \"STD_RR_Recovery\",\n",
    "            \"SD1_Rest\", \"SD2_Rest\",\n",
    "            \"SD1_Exercise\", \"SD2_Exercise\",\n",
    "            \"SD1_Recovery\", \"SD2_Recovery\"\n",
    "        ]\n",
    "        print(f\"Writing header to CSV: {header}\")\n",
    "        writer.writerow(header)\n",
    "        \n",
    "        # Step 3: Load the data from the file\n",
    "        try:\n",
    "            print(f\"Loading data from: {file_path}\")\n",
    "            data = np.loadtxt(file_path)\n",
    "            print(f\"Raw data shape: {data.shape}\")\n",
    "            \n",
    "            # Step 4: Filter out rows where the second column (HRV data) is zero\n",
    "            filtered_data = data[data[:, 1] != 0]\n",
    "            print(f\"Filtered data shape: {filtered_data.shape}\")\n",
    "            \n",
    "            # Split the data into time and HRV values\n",
    "            time_data = filtered_data[:, 0]\n",
    "            hrv_data = filtered_data[:, 1]\n",
    "            print(f\"Time data: {time_data[:5]}... (showing first 5 entries)\")\n",
    "            print(f\"HRV data: {hrv_data[:5]}... (showing first 5 entries)\")\n",
    "            \n",
    "            # Step 5: Calculate statistics\n",
    "            stats = calculate_interval_statistics(time_data, hrv_data)\n",
    "            print(f\"Calculated statistics: {stats}\")\n",
    "            \n",
    "            # Step 6: Build the CSV row\n",
    "            row = [os.path.basename(file_path)]\n",
    "            for region in ['Rest', 'Exercise', 'Recovery']:\n",
    "                if region in stats:\n",
    "                    row.extend([\n",
    "                        stats[region]['Mean'],\n",
    "                        stats[region]['Standard Deviation'],\n",
    "                        stats[region]['SD1'], \n",
    "                        stats[region]['SD2']\n",
    "                    ])\n",
    "                else:\n",
    "                    row.extend([None, None, None, None])\n",
    "            \n",
    "            print(f\"Constructed row for CSV: {row}\")\n",
    "            writer.writerow(row)\n",
    "\n",
    "            print(f\"File {filename} processed successfully and row written to CSV!\")\n",
    "\n",
    "        # Step 7: Error Handling\n",
    "        except ValueError as ve:\n",
    "            print(f\"ValueError for file {file_path}: {ve}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "# Dummy function to simulate statistics calculation\n",
    "def calculate_interval_statistics(time_data, hrv_data):\n",
    "    return {\n",
    "        \"Rest\": {\"Mean\": np.mean(hrv_data[:10]), \"Standard Deviation\": np.std(hrv_data[:10]), \"SD1\": 1, \"SD2\": 2},\n",
    "        \"Exercise\": {\"Mean\": np.mean(hrv_data[10:20]), \"Standard Deviation\": np.std(hrv_data[10:20]), \"SD1\": 1, \"SD2\": 2},\n",
    "        \"Recovery\": {\"Mean\": np.mean(hrv_data[20:]), \"Standard Deviation\": np.std(hrv_data[20:]), \"SD1\": 1, \"SD2\": 2}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ff0c6ee-111d-4918-beca-3cfe8485297f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: All/VPS50W.txt\n",
      "Writing header to CSV: ['File', 'Mean_RR_Rest', 'STD_RR_Rest', 'Mean_RR_Exercise', 'STD_RR_Exercise', 'Mean_RR_Recovery', 'STD_RR_Recovery', 'SD1_Rest', 'SD2_Rest', 'SD1_Exercise', 'SD2_Exercise', 'SD1_Recovery', 'SD2_Recovery']\n",
      "Loading data from: All/VPS50W.txt\n",
      "Raw data shape: (2129, 2)\n",
      "Filtered data shape: (2099, 2)\n",
      "Time data: [0.01616667 0.03431667 0.05105    0.06906667 0.08668333]... (showing first 5 entries)\n",
      "HRV data: [ 970. 1089. 1004. 1081. 1057.]... (showing first 5 entries)\n",
      "Calculated statistics: {'Rest': {'Mean': 1055.2, 'Standard Deviation': 43.924480645762905, 'SD1': 1, 'SD2': 2}, 'Exercise': {'Mean': 1023.2, 'Standard Deviation': 110.27764959410406, 'SD1': 1, 'SD2': 2}, 'Recovery': {'Mean': 891.97113997114, 'Standard Deviation': 120.08061719717381, 'SD1': 1, 'SD2': 2}}\n",
      "Constructed row for CSV: ['VPS50W.txt', 1055.2, 43.924480645762905, 1, 2, 1023.2, 110.27764959410406, 1, 2, 891.97113997114, 120.08061719717381, 1, 2]\n",
      "File VPS50W.txt processed successfully and row written to CSV!\n"
     ]
    }
   ],
   "source": [
    "process_file(data_folder, output_folder, csv_filename, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "481ec23e-1bd7-4ef4-97c6-54c1a1c41101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate RR mean, SD1, SD2, and standard deviation for each interval\n",
    "def calculate_interval_statistics(time_data, hrv_data):\n",
    "    intervals = {\n",
    "        'Rest': (1, 6),\n",
    "        'Exercise': (14, 19),\n",
    "        'Recovery': (25, 30)\n",
    "    }\n",
    "    \n",
    "    stats = {}\n",
    "    \n",
    "    for interval, (start, end) in intervals.items():\n",
    "        mask = (time_data >= start) & (time_data < end)\n",
    "        interval_data = hrv_data[mask]\n",
    "        \n",
    "        if len(interval_data) > 1:  # Ensure there's enough data for SD calculation\n",
    "            rr_mean = np.mean(interval_data)\n",
    "            sd1, sd2 = calculate_sd1_sd2(interval_data)\n",
    "            rr_std = np.std(interval_data)  # Calculate standard deviation\n",
    "            \n",
    "            # Print statistics for the current interval\n",
    "            print(f\"Interval: {interval}\")\n",
    "            print(f\"  Start: {start}, End: {end}\")\n",
    "            print(f\"  Mean: {rr_mean}\")\n",
    "            print(f\"  Standard Deviation: {rr_std}\")\n",
    "            print(f\"  SD1: {sd1}\")\n",
    "            print(f\"  SD2: {sd2}\")\n",
    "            print(\"\")\n",
    "\n",
    "            stats[interval] = {\n",
    "                'Mean': rr_mean,\n",
    "                'Standard Deviation': rr_std,\n",
    "                'SD1': sd1,\n",
    "                'SD2': sd2\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Not enough data for {interval} (available data points: {len(interval_data)})\")\n",
    "            print(\"\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Dummy function to simulate SD1 and SD2 calculation\n",
    "def calculate_sd1_sd2(data):\n",
    "    # Placeholder for actual SD1 and SD2 calculations; using fixed values for demonstration\n",
    "    return 1, 2  # Replace with actual calculations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cedd1df-b3d2-4c9c-8026-03865c638d96",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m calculate_sd1_sd2(data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "calculate_sd1_sd2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a6b9e-c53a-461c-8b96-00b4725f1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_interval_statistics(time_data, hrv_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
